{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Training notebook for [Diff-SVC](https://github.com/prophesier/diff-svc) originally made by [justinjohn-03](https://github.com/justinjohn0306)\n",
        " Modified by [奕晨](https://twitter.com/nekrothecorpse) of [Archivoice](https://github.com/archivoice) and currently maintained by [haru0l](https://twitter.com/mscoocoo2)\n",
        "\n",
        "This is the basic version of the notebook. This notebook assumes that you have READ the documentation and no support will be given.\n",
        "\n",
        "QOL improvements has been removed in this version due to a certain someone that won't credit the usage of the program."
      ],
      "metadata": {
        "id": "qI-wDbQDmSjx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation"
      ],
      "metadata": {
        "id": "MGNHNSGcEFHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!rm -rf sample_data\n",
        "!python -m pip install --upgrade pip wheel --quiet\n",
        "!pip uninstall gdown -y --quiet\n",
        "#!pip install git+https://github.com/justinjohn0306/gdown.git --quiet\n",
        "!pip install pydub fuzzywuzzy python-Levenshtein pyworld==0.3.1 --quiet\n",
        "\n",
        "#install aria2\n",
        "!sudo apt-get install aria2  &> /dev/null\n",
        "!apt install wget curl ca-certificates &> /dev/null\n",
        "!wget -N git.io/aria2.sh &> /dev/null && chmod +x aria2.sh &> /dev/null\n",
        "!echo 1|./aria2.sh &> /dev/null\n",
        "!echo 12|./aria2.sh &> /dev/null\n",
        "!echo 6|./aria2.sh &> /dev/null\n",
        "!pip install --pre torchtext==0.6.0 --no-deps --quiet\n",
        "\n",
        "\n",
        "#@markdown ###Model sample rate\n",
        "#@markdown Please choose if you want to train a 24kHz model or a 44.1kHz model.\n",
        "sample_rate = '44.1kHz' #@param [\"24kHz\", \"44.1kHz\"]\n",
        "\n",
        "print('Installing Diff-SVC')\n",
        "!git clone -q https://github.com/prophesier/diff-svc\n",
        "\n",
        "%cd \"diff-svc\"\n",
        "!pip install -r requirements_short.txt --quiet\n",
        "!pip install tensorboard<2.9,>=2.8 --quiet\n",
        "#!pip install --upgrade numpy==1.23.0 scipy==1.9.3 --quiet\n",
        "%reload_ext tensorboard\n",
        "\n",
        "%mkdir -p checkpoints\n",
        "\n",
        "hifigan_24k = \"https://github.com/haru0l/Diff-SVC-notebooks/releases/download/models_24khz/hifigan_24k.zip\"\n",
        "hifigan_44k = \"https://github.com/haru0l/Diff-SVC-notebooks/releases/download/start/hifigan_44k.zip\"\n",
        "checkpoints = \"https://github.com/haru0l/Diff-SVC-notebooks/releases/download/start/checkpoints.zip\"\n",
        "\n",
        "!aria2c --file-allocation=none -c -x 10 -s 10 {checkpoints} -q\n",
        "!unzip checkpoints.zip\n",
        "!rm checkpoints.zip\n",
        "\n",
        "if sample_rate == \"44.1kHz\":\n",
        "\t!aria2c --file-allocation=none -c -x 10 -s 10 {hifigan_44k} -q\n",
        "\t!unzip hifigan_44k.zip -d checkpoints\n",
        "\t!rm hifigan_44k.zip\n",
        "\tconfig_path = \"training/config_nsf.yaml\"\n",
        "\tslay = \"44100\"\n",
        "else:\n",
        "\t!aria2c --file-allocation=none -c -x 10 -s 10 {hifigan_24k} -q\n",
        "\t!unzip hifigan_24k.zip\n",
        "\t!rm hifigan_24k.zip\n",
        "\tconfig_path = \"training/config.yaml\"\n",
        "\t!rm {config_path}\n",
        "\t!wget \"https://github.com/haru0l/Diff-SVC-notebooks/releases/download/models_24khz/config.yaml\" -O {config_path} -q\n",
        "\tslay = \"24000\"\n",
        "clear_output()\n",
        "print('Done!')"
      ],
      "metadata": {
        "id": "IYxufeQ9EKuY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are now expected to extract the wavs into data/raw/(singer_name_here)"
      ],
      "metadata": {
        "id": "XTvZzqU-FSKI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "4s-RqXnR-UOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Pre-processing\n",
        "#@markdown This just converts your data into mel spectograms\n",
        "\n",
        "os.environ['PYTHONPATH']='.'\n",
        "!CUDA_VISIBLE_DEVICES=0 python preprocessing/binarize.py --config {config_path}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wsHTxKEO-ZwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Training\n",
        "#@markdown Trains your model.\n",
        "\n",
        "os.environ['PYTHONPATH']='.'\n",
        "!CUDA_VISIBLE_DEVICES=0 python run.py --config {config_path} --exp_name $singer_name --reset"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NvlB1oCR_lxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference Section**"
      ],
      "metadata": {
        "id": "t8k1skYjXXo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "#@title # **Load model**\n",
        "\n",
        "#@markdown ### **Load a trained model for inferencing**\n",
        "#@markdown ___\n",
        "#@markdown Note: Add the full path of the FOLDER of your model. This will automatically load the latest model along with your configs.\n",
        " \n",
        "with open(config_path, 'r') as config_file:\n",
        "    config = yaml.safe_load(config_file)\n",
        "    singer_name = config['speaker_id']\n",
        "\n",
        "os.environ['PYTHONPATH']='.'\n",
        "!CUDA_VISIBLE_DEVICES=0\n",
        "\n",
        "from utils.hparams import hparams\n",
        "from preprocessing.data_gen_utils import get_pitch_parselmouth,get_pitch_crepe\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import utils\n",
        "import librosa\n",
        "import torchcrepe\n",
        "from infer import *\n",
        "import logging\n",
        "from infer_tools.infer_tool import *\n",
        "\n",
        "logging.getLogger('numba').setLevel(logging.WARNING)\n",
        "\n",
        "def find_latest_ckpt(dir_path):\n",
        "    try:\n",
        "      ckpt_files = [f for f in os.listdir(dir_path) if f.endswith('.ckpt')]\n",
        "      ckpt_files.sort()\n",
        "      return os.path.join(dir_path, ckpt_files[-1])\n",
        "    except Exception as e:\n",
        "      print(\"Unable to find model/model is corrupted.\")\n",
        "      error_inference = True\n",
        "\n",
        "model_folder = \"\" #@param {type: \"string\"}\n",
        "# Example usage\n",
        "model_path = find_latest_ckpt(f'{model_folder}')\n",
        "\n",
        "project_name = \"sample\"\n",
        "config_path= f\"{model_folder}/config.yaml\"\n",
        "hubert_gpu=True\n",
        "svc_model = Svc(project_name,config_path,hubert_gpu, model_path)\n",
        "print('model loaded')\n",
        "\n",
        "#@title Run Inference (yes I'm keeping this image here incase someone want to kidly buy our ko-fi <3)\n",
        "\n",
        "#@markdown put your wav paths in here\n",
        "wav_in = \"\" #@param {type:\"string\"}\n",
        "\n",
        "key = 0 #@param {type:\"slider\", min:-12, max:12, step:1}\n",
        "\n",
        "pndm_speedup = 20 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "\n",
        "wav_out = \"sample\"\n",
        "\n",
        "add_noise_step = 500 #@param {type:\"slider\", min:0, max:1000, step:10}\n",
        "\n",
        "\n",
        "thre = 0.05 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "use_crepe= False #@param {type:\"boolean\"}\n",
        "use_pe=False #@param {type:\"boolean\"}\n",
        "use_gt_mel= False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "try:\n",
        "  f0_tst, f0_pred, audio = run_clip(svc_model,file_path=wav_in, key=key, acc=pndm_speedup, use_crepe=use_crepe, use_pe=use_pe, thre=thre, use_gt_mel=use_gt_mel, add_noise_step=add_noise_step,project_name=project_name,out_path=f\"results/{wav_out}.flac\")\n",
        "  clear_output()\n",
        "  print(\"Inference complete!\")\n",
        "  print(f\"Inferenced file is stored at results/{wav_out}.flac.\")\n",
        "except Exception as e:\n",
        "  print(\"Unable to inference.\")\n",
        "  print(\"Here's a cat meowing though for 4 minutes.\")\n",
        "\n",
        "from IPython.display import Audio\n",
        "Audio(f\"{link}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NuKR8QZOyVnH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}